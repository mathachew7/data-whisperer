# Data Whisperer

**Data Whisperer** is an AI-powered co-pilot for your data pipelines.  
It answers your questions about pipeline events, failures, and anomalies by combining fast vector search (ChromaDB) with GPT-4 for contextual understanding.

---

## ğŸš€ Features

âœ… Ask pipeline-related questions like:
- "What happened at 3 PM yesterday?"
- "Why did Task X fail?"
- "Any delays in the system?"

- âœ… Upload logs via JSON or CSV  
- âœ… ChromaDB for fast vector search  
- âœ… SentenceTransformer for embeddings  
- âœ… GPT-4 for intelligent context interpretation  
- âœ… Modular FastAPI backend  
- âœ… System logs with SQLite for debugging and monitoring  
- âœ… Pydantic validation for input data  
- âœ… API endpoints for logs, questions, and system logs  
-âœ… JSON and CSV file support for uploading pipeline data

---

## ğŸ§‘â€ğŸ’» How to Run Locally

### 1ï¸âƒ£ Clone the repo & set up environment

```bash
git clone https://github.com/yourname/data-whisperer.git
cd data-whisperer/backend
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

```


### 2ï¸âƒ£ Add your OpenAI API Key

Create a `.env` file inside `backend/`:

```ini
OPENAI_API_KEY=sk-xxx-your-key-here
```

### 3ï¸âƒ£ Load pipeline data into Chroma (optional for testing)

```bash
python scripts/load_to_chroma.py
```

### 4ï¸âƒ£ Run the FastAPI backend

```bash
uvicorn app.main:app --reload
```

Access the API at:

```bash
http://127.0.0.1:8000/docs
```

---

## ğŸ“¦ API Endpoints

| Endpoint       | Method | Description                                                                                           |
|----------------|--------|-------------------------------------------------------------------------------------------------------|
| `/ask`         | POST   | Ask questions about logs and pipelines                                                                |
| `/upload`      | POST   | Upload logs in JSON/CSV format                                                                        |
| `/system-logs` | GET    | etrieve internal system logs stored in SQLite (e.g., system events, queries, API calls).              |

Example
```json
[
  { "id": "log-1", "content": "Task X failed at 3 PM." },
  { "id": "log-2", "content": "Pipeline Y delayed due to retries." }
]

```
---

## ğŸ—ï¸ Project Structure

```bash
data-whisperer/
â”œâ”€â”€ .gitignore
â””â”€â”€ backend/
    â”œâ”€â”€ .env
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ api/
    â”‚   â”‚   â”œâ”€â”€ routes.py
    â”‚   â”‚   â”œâ”€â”€ api_fetcher.py
    â”‚   â”œâ”€â”€ core/
    â”‚   â”‚   â”œâ”€â”€ logger.py
    â”‚   â”‚   â”œâ”€â”€ services.py
    â”‚   â”‚   â”œâ”€â”€ vector_db.py
    â”‚   â”‚   â”œâ”€â”€ preprocessor.py
    â”‚   â”œâ”€â”€ main.py
    â”œâ”€â”€ chroma_data/
    â”œâ”€â”€ logs/
    â”‚   â””â”€â”€ system_logs.db
    â”œâ”€â”€ pipeline_data/
    â”‚   â””â”€â”€ logs.json
    â”œâ”€â”€ scripts/
    â”‚   â””â”€â”€ load_to_chroma.py
    â”œâ”€â”€ venv/
    â””â”€â”€ README.md
```

---

## ğŸ”’ Notes

- `.env`, `chroma_data/`, and `logs/system_logs.db` are git-ignored for security.

- Replace `logs.json` with your own pipeline data for real use cases.

- All system activities (e.g., API calls, file uploads, questions) are logged in `logs/system_logs.db`.

- The `/system-logs` endpoint provides easy access to these logs for audit and debugging purposes.

---
## ğŸŒ Example Questions

```json
POST /ask
{
  "question": "What caused the delay in Task Y yesterday?"
}

```
---

## ğŸ”¥ License

MIT License

---

## ğŸ‘‘ Author

Built with â¤ï¸ by **Subash Yadav**  
Letâ€™s build the future of data pipelines together! ğŸš€
